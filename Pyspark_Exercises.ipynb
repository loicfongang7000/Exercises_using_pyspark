{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ef8966c",
   "metadata": {},
   "source": [
    "# Quelques Exercises faits avec Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a2930f",
   "metadata": {},
   "source": [
    "### a) Implémentez une fonction pour générer une liste aléatoire de triplet. Le premier élément doit être un int allant de 0 à n sans doublons. Le second élément est un entier variant de 0 à 50 et le dernier un entier entre 0 et 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09b1b6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8, 46, 2), (3, 26, 1), (5, 14, 4), (0, 4, 1), (7, 7, 3), (9, 2, 1), (10, 4, 5), (6, 48, 2), (1, 23, 1), (4, 27, 1), (2, 21, 4)]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame \n",
    "from pyspark.sql.functions import min, max, col, coalesce, lit\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "def generer_liste_triplets(n):\n",
    "    \n",
    "\n",
    "    ids = list(range(n+1))          \n",
    "    random.shuffle(ids)             \n",
    "\n",
    "    triplets = []\n",
    "\n",
    "    for i in ids:\n",
    "        value1 = random.randint(0, 50)\n",
    "        value2 = random.randint(0, 5)\n",
    "        triplets.append((i, value1, value2))\n",
    "\n",
    "    return triplets\n",
    "\n",
    "liste_triplets = generer_liste_triplets(10)\n",
    "\n",
    "print(liste_triplets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ad9538",
   "metadata": {},
   "source": [
    "### b) Implémentez la fonction init_df(nb_rows:int) -> DataFrame permettant de générer un DataFrame aléatoire de taille nb_rows et ayant trois colonnes : id, value1, value2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f404335f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+\n",
      "| id|value1|value2|\n",
      "+---+------+------+\n",
      "|  9|    48|     0|\n",
      "|  1|    25|     0|\n",
      "|  3|    30|     4|\n",
      "|  8|     4|     5|\n",
      "|  0|    27|     0|\n",
      "|  7|     3|     5|\n",
      "|  5|    38|     4|\n",
      "|  2|    19|     3|\n",
      "|  4|    33|     3|\n",
      "|  6|    41|     4|\n",
      "+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySparkHomework\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "def init_df(nb_rows:int) -> DataFrame:\n",
    "\n",
    "    data = generer_liste_triplets(nb_rows-1)\n",
    "    df = spark.createDataFrame(data,[\"id\", \"value1\", \"value2\"])     #Génération de Dataframe aléatoire \n",
    "\n",
    "    return df\n",
    "\n",
    "df_aleatoire = init_df(10)  \n",
    "\n",
    "df_aleatoire.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95eb2ec",
   "metadata": {},
   "source": [
    "### c) Implémentez la fonction transformation(df:DataFrame) -> DataFrame qui\n",
    "### • normalise value1 entre 0 et 1 ;\n",
    "### • ajoute une colonne ratio = value1 / value2 ;\n",
    "### • filtre les colonnes dont le ratio est inférieur au ratio median.\n",
    "### • retourne le résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d018c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+------+-------------------+\n",
      "| id|            value1|value2|              ratio|\n",
      "+---+------------------+------+-------------------+\n",
      "|  3|               0.6|     4|               0.15|\n",
      "|  5|0.7777777777777778|     4|0.19444444444444445|\n",
      "|  4|0.6666666666666666|     3| 0.2222222222222222|\n",
      "|  6|0.8444444444444444|     4| 0.2111111111111111|\n",
      "+---+------------------+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def transformation(df: DataFrame) -> DataFrame:\n",
    "    # Normalisation de value1\n",
    "    stats = df.agg(\n",
    "        min(\"value1\").alias(\"min_v\"),\n",
    "        max(\"value1\").alias(\"max_v\")\n",
    "    ).collect()[0]\n",
    "\n",
    "    min_v = stats[\"min_v\"]\n",
    "    max_v = stats[\"max_v\"]\n",
    "\n",
    "    df = df.withColumn(\n",
    "        \"value1\",\n",
    "        (col(\"value1\") - min_v) / (max_v - min_v)\n",
    "    )\n",
    "\n",
    "    # Suppression des value2 = 0\n",
    "    df = df.filter(col(\"value2\") != 0)\n",
    "\n",
    "    # Ajout du ratio\n",
    "    df = df.withColumn(\n",
    "        \"ratio\",\n",
    "        col(\"value1\") / col(\"value2\")\n",
    "    )\n",
    "\n",
    "    # Médiane du ratio\n",
    "    median_ratio = df.approxQuantile(\"ratio\", [0.5], 0.0)[0]\n",
    "\n",
    "    # Filtrage \n",
    "    df = df.filter(col(\"ratio\") >= median_ratio)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_transfomation = transformation(df_aleatoire)  \n",
    "\n",
    "df_transfomation.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2d8849",
   "metadata": {},
   "source": [
    "### d) Implémentez la fonction merge(df1, df2) prenant 2 DataFrame un DataFrame représentant la fusion des deux :\n",
    "### • Les lignes de même IDs voient leurs valeurs ajoutées (pensez à mettre le ratio à jour)\n",
    "### • Les lignes sans équivalent d’ID sont ajoutées telles quelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7406718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------------------+\n",
      "| id|value1|value2|             ratio|\n",
      "+---+------+------+------------------+\n",
      "|  0|   0.0|     5|               0.0|\n",
      "|  1|  32.0|     4|               8.0|\n",
      "|  2|18.525|     2|            9.2625|\n",
      "|  3|  49.0|     0|              NULL|\n",
      "|  4|  38.0|     2|              19.0|\n",
      "|  5|  43.0|     3|14.333333333333334|\n",
      "|  6|50.325|     7| 7.189285714285715|\n",
      "|  7|  47.0|    10|               4.7|\n",
      "|  8| 11.75|     5|              2.35|\n",
      "|  9|  28.0|     1|              28.0|\n",
      "+---+------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def merge(df1: DataFrame, df2: DataFrame) -> DataFrame:\n",
    "\n",
    "    # Jointure complète sur id\n",
    "    joined = df1.alias(\"df1\").join(\n",
    "        df2.alias(\"df2\"),\n",
    "        on=\"id\",\n",
    "        how=\"outer\"\n",
    "    )\n",
    "\n",
    "    # Addition des colonnes (null -> 0)\n",
    "    result = joined.select(\n",
    "        col(\"id\"),\n",
    "\n",
    "        (\n",
    "            coalesce(col(\"df1.value1\"), lit(0)) +\n",
    "            coalesce(col(\"df2.value1\"), lit(0))\n",
    "        ).alias(\"value1\"),\n",
    "\n",
    "        (\n",
    "            coalesce(col(\"df1.value2\"), lit(0)) +\n",
    "            coalesce(col(\"df2.value2\"), lit(0))\n",
    "        ).alias(\"value2\")\n",
    "    )\n",
    "\n",
    "    # Recalcul du ratio\n",
    "    result = result.withColumn(\n",
    "        \"ratio\",\n",
    "        col(\"value1\") / col(\"value2\")\n",
    "    )\n",
    "\n",
    "    return result\n",
    "\n",
    "x = transformation(init_df(10))\n",
    "\n",
    "y= merge(init_df(10), x) #fusion du Dataframe init_df(10) et du dataframe x\n",
    "y.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
